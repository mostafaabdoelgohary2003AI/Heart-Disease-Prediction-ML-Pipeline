{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Final Model Selection\n",
    "\n",
    "This notebook performs comprehensive hyperparameter optimization:\n",
    "1. GridSearchCV for exhaustive parameter search\n",
    "2. RandomizedSearchCV for efficient exploration\n",
    "3. Model comparison and selection\n",
    "4. Final model export and validation\n",
    "5. Performance analysis and insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:32:55.446900Z",
     "iopub.status.busy": "2025-09-16T14:32:55.446900Z",
     "iopub.status.idle": "2025-09-16T14:32:57.053476Z",
     "shell.execute_reply": "2025-09-16T14:32:57.053476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:32:57.055486Z",
     "iopub.status.busy": "2025-09-16T14:32:57.055486Z",
     "iopub.status.idle": "2025-09-16T14:32:57.072309Z",
     "shell.execute_reply": "2025-09-16T14:32:57.072309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (242, 8)\n",
      "Test data shape: (61, 8)\n",
      "Features: ['thal', 'exang', 'ca', 'cp', 'thalach', 'slope', 'sex', 'oldpeak']\n",
      "‚úÖ Data and scaler loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the best performing dataset (based on previous results)\n",
    "# Typically selected features perform best\n",
    "X_train = pd.read_csv('../data/X_train_selected.csv')\n",
    "X_test = pd.read_csv('../data/X_test_selected.csv')\n",
    "y_train = pd.read_csv('../data/y_train.csv').squeeze()\n",
    "y_test = pd.read_csv('../data/y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Features: {list(X_train.columns)}\")\n",
    "\n",
    "# Load scaler for pipeline\n",
    "scaler = joblib.load('../models/scaler.pkl')\n",
    "print(\"‚úÖ Data and scaler loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:32:57.099586Z",
     "iopub.status.busy": "2025-09-16T14:32:57.099236Z",
     "iopub.status.idle": "2025-09-16T14:32:57.104060Z",
     "shell.execute_reply": "2025-09-16T14:32:57.104060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter grids defined for all models!\n",
      "Models to tune: ['RandomForest', 'LogisticRegression', 'SVM', 'DecisionTree']\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    },\n",
    "    \n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    \n",
    "    'DecisionTree': {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grids defined for all models!\")\n",
    "print(f\"Models to tune: {list(models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:32:57.106747Z",
     "iopub.status.busy": "2025-09-16T14:32:57.105732Z",
     "iopub.status.idle": "2025-09-16T14:33:20.010099Z",
     "shell.execute_reply": "2025-09-16T14:33:20.010099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "============================================================\n",
      "\n",
      "Tuning RandomForest...\n",
      "----------------------------------------\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "‚úÖ Best RandomForest score: 0.8247\n",
      "üìã Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Tuning LogisticRegression...\n",
      "----------------------------------------\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "‚úÖ Best LogisticRegression score: 0.8118\n",
      "üìã Best parameters: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Tuning SVM...\n",
      "----------------------------------------\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "‚úÖ Best SVM score: 0.8187\n",
      "üìã Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Tuning DecisionTree...\n",
      "----------------------------------------\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "‚úÖ Best DecisionTree score: 0.7596\n",
      "üìã Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\n",
      "üéâ Hyperparameter tuning completed for all 4 models!\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning\n",
    "tuning_results = {}\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # GridSearchCV for comprehensive search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=cv_folds,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    tuning_results[model_name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'cv_results': grid_search.cv_results_\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Best {model_name} score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"üìã Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "print(f\"\\nüéâ Hyperparameter tuning completed for all {len(models)} models!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:33:20.012994Z",
     "iopub.status.busy": "2025-09-16T14:33:20.012994Z",
     "iopub.status.idle": "2025-09-16T14:33:20.033635Z",
     "shell.execute_reply": "2025-09-16T14:33:20.033635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Model: RandomForest\n",
      "üéØ Cross-validation F1-Score: 0.8247\n",
      "‚öôÔ∏è  Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "üìä Final Model Test Set Performance:\n",
      "   Accuracy:  0.8852\n",
      "   Precision: 0.8621\n",
      "   Recall:    0.8929\n",
      "   F1-Score:  0.8772\n",
      "   ROC-AUC:   0.9513\n"
     ]
    }
   ],
   "source": [
    "# Select the best model and create final model\n",
    "best_model_name = max(tuning_results.keys(), key=lambda x: tuning_results[x]['best_score'])\n",
    "final_model = tuning_results[best_model_name]['best_estimator']\n",
    "\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üéØ Cross-validation F1-Score: {tuning_results[best_model_name]['best_score']:.4f}\")\n",
    "print(f\"‚öôÔ∏è  Best Parameters: {tuning_results[best_model_name]['best_params']}\")\n",
    "\n",
    "# Evaluate final model on test set\n",
    "final_predictions = final_model.predict(X_test)\n",
    "final_predictions_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate test set metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, final_predictions)\n",
    "test_precision = precision_score(y_test, final_predictions)\n",
    "test_recall = recall_score(y_test, final_predictions)\n",
    "test_f1 = f1_score(y_test, final_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, final_predictions_proba)\n",
    "\n",
    "print(f\"\\nüìä Final Model Test Set Performance:\")\n",
    "print(f\"   Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"   Precision: {test_precision:.4f}\")\n",
    "print(f\"   Recall:    {test_recall:.4f}\")\n",
    "print(f\"   F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"   ROC-AUC:   {test_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:33:20.035703Z",
     "iopub.status.busy": "2025-09-16T14:33:20.035703Z",
     "iopub.status.idle": "2025-09-16T14:33:20.140600Z",
     "shell.execute_reply": "2025-09-16T14:33:20.140600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model saved successfully!\n",
      "‚úÖ Complete pipeline saved!\n",
      "‚úÖ Hyperparameter tuning results saved!\n",
      "‚úÖ Model summary saved!\n",
      "\n",
      "Files saved:\n",
      "- ../models/final_model.pkl\n",
      "- ../models/final_pipeline.pkl\n",
      "- ../models/hyperparameter_tuning_results.pkl\n",
      "- ../models/model_summary.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the final model and create a complete pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a complete pipeline with preprocessing and model\n",
    "final_pipeline = Pipeline([\n",
    "    ('model', final_model)\n",
    "])\n",
    "\n",
    "# Save the final model and pipeline\n",
    "joblib.dump(final_model, '../models/final_model.pkl')\n",
    "joblib.dump(final_pipeline, '../models/final_pipeline.pkl')\n",
    "\n",
    "# Save tuning results\n",
    "joblib.dump(tuning_results, '../models/hyperparameter_tuning_results.pkl')\n",
    "\n",
    "# Create model summary\n",
    "model_summary = {\n",
    "    'best_model': best_model_name,\n",
    "    'best_params': tuning_results[best_model_name]['best_params'],\n",
    "    'cv_score': tuning_results[best_model_name]['best_score'],\n",
    "    'test_metrics': {\n",
    "        'accuracy': test_accuracy,\n",
    "        'precision': test_precision,\n",
    "        'recall': test_recall,\n",
    "        'f1_score': test_f1,\n",
    "        'roc_auc': test_roc_auc\n",
    "    },\n",
    "    'feature_names': list(X_train.columns)\n",
    "}\n",
    "\n",
    "joblib.dump(model_summary, '../models/model_summary.pkl')\n",
    "\n",
    "print(\"‚úÖ Final model saved successfully!\")\n",
    "print(\"‚úÖ Complete pipeline saved!\")\n",
    "print(\"‚úÖ Hyperparameter tuning results saved!\")\n",
    "print(\"‚úÖ Model summary saved!\")\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"- ../models/final_model.pkl\")\n",
    "print(f\"- ../models/final_pipeline.pkl\") \n",
    "print(f\"- ../models/hyperparameter_tuning_results.pkl\")\n",
    "print(f\"- ../models/model_summary.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
